{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOrsZxeKATxiYAmoN822mJQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.preprocessing import LabelEncoder, StandardScaler\n","from sklearn.model_selection import train_test_split, cross_val_score, KFold, RandomizedSearchCV\n","from sklearn.metrics import mean_squared_error, make_scorer\n","from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n","from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n","from sklearn.preprocessing import PolynomialFeatures\n","from sklearn.pipeline import Pipeline\n","from xgboost import XGBRegressor\n","from lightgbm import LGBMRegressor\n","import warnings\n","warnings.filterwarnings('ignore')"],"metadata":{"id":"Hj0RywJRXQvr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# upload train dataset\n","from google.colab import files\n","\n","# Open file picker\n","uploaded = files.upload()\n","train_df = pd.read_csv(\"train_v9rqX0R.csv\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":75},"id":"WudP9Lu1XRsK","executionInfo":{"status":"ok","timestamp":1755326718050,"user_tz":-330,"elapsed":14152,"user":{"displayName":"Vamshi Mohan","userId":"00739284468631637860"}},"outputId":"72c08e82-dd45-4790-88b1-61af8248595c"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-d199de65-b82d-4943-9a7a-d8dc6d31a5d2\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-d199de65-b82d-4943-9a7a-d8dc6d31a5d2\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving train_v9rqX0R.csv to train_v9rqX0R.csv\n"]}]},{"cell_type":"code","source":["# upload test dataset\n","from google.colab import files\n","\n","# Open file picker\n","uploaded = files.upload()\n","valid_df = pd.read_csv(\"test_AbJTz2l.csv\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":75},"id":"YK0-rUJFXYh5","executionInfo":{"status":"ok","timestamp":1755326727624,"user_tz":-330,"elapsed":9547,"user":{"displayName":"Vamshi Mohan","userId":"00739284468631637860"}},"outputId":"fe60ab2a-43f1-4979-b912-5f3c83493730"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-161d2f4b-6a82-4a9d-813d-6a540459b492\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-161d2f4b-6a82-4a9d-813d-6a540459b492\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving test_AbJTz2l.csv to test_AbJTz2l.csv\n"]}]},{"cell_type":"code","source":["# --- Load data in jupyter notebook ---\n","# train_df = pd.read_csv(\"train.csv\")\n","# valid_df = pd.read_csv(\"test.csv\")"],"metadata":{"id":"XRZUMZ4OPe1P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df.head()"],"metadata":{"id":"coXnvVhCGnJU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df.info()"],"metadata":{"id":"FtxB3-0xGs-A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# check null values\n","train_df.isnull().sum(axis=0)"],"metadata":{"id":"S1p3G7IrGun7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 1) Items in Column 'Item_Fat_Content' has variable naming. Standardize Item_Fat_Content\n","train_df['Item_Fat_Content'] = train_df['Item_Fat_Content'].replace({\n","    'low fat': 'Low Fat',\n","    'LF': 'Low Fat',\n","    'reg': 'Regular'\n","})\n","valid_df['Item_Fat_Content'] = valid_df['Item_Fat_Content'].replace({\n","    'low fat': 'Low Fat',\n","    'LF': 'Low Fat',\n","    'reg': 'Regular'\n","})"],"metadata":{"id":"__duguWWG8xx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df.head()"],"metadata":{"id":"xdPrfYdUHJMJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # 1) Handle missing values in column \"Outlet_Size\"\n","# Outlet size may depend on outlet stablishment year, outlet type and output location type. So, skipping these rows or just filling \"Small\" may not bbe efficient\n","# so matrix comparison using cross table would be useful to undestand their relationship\n","\n","crosstable = pd.crosstab(\n","    index=df['Outlet_Size'],\n","    columns=[df['Outlet_Type'], df['Outlet_Establishment_Year']]\n",")\n","crosstable"],"metadata":{"id":"TSxoWsotHdqk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 2) Handle missing values in Outlet_Size. Grocery Store is categorized as Small. Supermarket Type2 and Supermarket Type3 are Medium. Supermarket Type1 has all three categories (so do not consider)\n","size_map = {\n","    'Grocery Store': 'Small',\n","    'Supermarket Type2': 'Medium',\n","    'Supermarket Type3': 'Medium'\n","}\n","train_df['Outlet_Size'] = train_df['Outlet_Size'].fillna(train_df['Outlet_Type'].map(size_map))\n","valid_df['Outlet_Size'] = valid_df['Outlet_Size'].fillna(valid_df['Outlet_Type'].map(size_map))"],"metadata":{"id":"Xwpc6TLIHCQt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df.head()"],"metadata":{"id":"5DDHU5DwHV1t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Still some values of Outlet_Size are zero"],"metadata":{"id":"jjWv3HWUHoa7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["crosstable = pd.crosstab(\n","    index=df['Outlet_Size'],\n","    columns=df['Outlet_Location_Type']\n",")\n","crosstable"],"metadata":{"id":"CzXtVvlKHxxo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 2.1) Handle missing values based on Outlet_Location_Type. As Tier 2 is categorized under Small in crosstable\n","size_map2 = {'Tier 2': 'Small'}\n","train_df['Outlet_Size'] = train_df['Outlet_Size'].fillna(train_df['Outlet_Location_Type'].map(size_map2))\n","valid_df['Outlet_Size'] = valid_df['Outlet_Size'].fillna(valid_df['Outlet_Location_Type'].map(size_map2))"],"metadata":{"id":"SrUb_ox1HVrn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df.head()"],"metadata":{"id":"cgnPjgyKHLqA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 3) Handle missing values in Item_Weight. Group Item_Weight based on Item_Identifier and fill the mean value\n","train_df['Item_Weight'] = train_df['Item_Weight'].fillna(train_df.groupby(['Item_Identifier'])['Item_Weight'].transform('mean'))\n","valid_df['Item_Weight'] = valid_df['Item_Weight'].fillna(valid_df.groupby(['Item_Identifier'])['Item_Weight'].transform('mean'))"],"metadata":{"id":"FUlr-27EIS4p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df.isnull(sum=0)"],"metadata":{"id":"_C-joRohIiCM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Still there are missing values in Item_Weight. Group them based on Item_Type and fill the mean value\n","train_df['Item_Weight'] = train_df['Item_Weight'].fillna(train_df.groupby('Item_Type')['Item_Weight'].transform('mean'))\n","valid_df['Item_Weight'] = valid_df['Item_Weight'].fillna(valid_df.groupby('Item_Type')['Item_Weight'].transform('mean'))"],"metadata":{"id":"jMBo4nGvIheo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 4) Handle zeros in Item_Visibility. Group by Item_Identifier and fill in the mean values\n","train_df['Item_Visibility'] = train_df.groupby('Item_Identifier')['Item_Visibility'].transform(\n","    lambda x: x.replace(0, x.mean())\n",")\n","valid_df['Item_Visibility'] = valid_df.groupby('Item_Identifier')['Item_Visibility'].transform(\n","    lambda x: x.replace(0, x.mean())\n",")\n","\n","# Some values are still zero in validation set. As they don't multiple products (repeated Item_Identifier). Fill remaining zeros in test\n","valid_df['Item_Visibility'] = valid_df.groupby(['Item_Type', 'Item_Fat_Content'])['Item_Visibility'].transform('mean')"],"metadata":{"id":"jjzy7vCHIz1K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# --- Calculate Outlet_Age. As it has an effect on sales\n","train_df['Outlet_Age'] = 2025 - train_df['Outlet_Establishment_Year']\n","valid_df['Outlet_Age'] = 2025 - valid_df['Outlet_Establishment_Year']"],"metadata":{"id":"6tBa63qrJQQ3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# --- Encoding string columns\n","# Item_Fat_Content → 1,2\n","train_df['Item_Fat_Content'] = train_df['Item_Fat_Content'].replace({'Low Fat': 1, 'Regular': 2})\n","valid_df['Item_Fat_Content'] = valid_df['Item_Fat_Content'].replace({'Low Fat': 1, 'Regular': 2})\n","\n","# Outlet_Size → 1,2,3\n","train_df['Outlet_Size'] = train_df['Outlet_Size'].replace({'Small': 1, 'Medium': 2, 'High': 3})\n","valid_df['Outlet_Size'] = valid_df['Outlet_Size'].replace({'Small': 1, 'Medium': 2, 'High': 3})\n","\n","# Outlet_Location_Type → 1,2,3\n","train_df['Outlet_Location_Type'] = train_df['Outlet_Location_Type'].replace({'Tier 1': 1, 'Tier 2': 2, 'Tier 3': 3})\n","valid_df['Outlet_Location_Type'] = valid_df['Outlet_Location_Type'].replace({'Tier 1': 1, 'Tier 2': 2, 'Tier 3': 3})\n","\n","# Outlet_Type → 1,2,3,4\n","outlet_type_map = {\n","    'Grocery Store': 1,\n","    'Supermarket Type1': 2,\n","    'Supermarket Type2': 3,\n","    'Supermarket Type3': 4\n","}\n","train_df['Outlet_Type'] = train_df['Outlet_Type'].replace(outlet_type_map)\n","valid_df['Outlet_Type'] = valid_df['Outlet_Type'].replace(outlet_type_map)\n","\n","# --- Encode Item_Type as 1,2,3,... ---\n","train_df['Item_Type'], uniques = pd.factorize(train_df['Item_Type'])\n","valid_df['Item_Type'] = pd.Categorical(valid_df['Item_Type'], categories=uniques).codes\n","\n","train_df['Item_Type'] = train_df['Item_Type'] + 1\n","valid_df['Item_Type'] = valid_df['Item_Type'] + 1"],"metadata":{"id":"neUkDpbKJdR4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# --- Without Feature Engineering, XGBoost RMSE obtained a saturation of 1089, Linear Regression RMSE 1212, Polynomial Regression RMSE 1090, Randon Forest RMSE 1132\n","\n","# --- Feature Engineering 1 : Item_Sales_Frequency ---\n","# ---------- Trial 1 - xgboost rmse - 1041 (Lowest rmse mentioned)\n","#train_df['Item_Sales_Frequency'] = train_df['Outlet_Age'] * (train_df['Item_MRP'] - train_df['Item_Visibility'])/(train_df['Item_Weight'] + 1)\n","#valid_df['Item_Sales_Frequency'] = valid_df['Outlet_Age'] * (valid_df['Item_MRP'] - valid_df['Item_Visibility'])/(valid_df['Item_Weight'] + 1)\n","\n","#item_popularity = train_df['Item_Identifier'].value_counts(normalize=True)  # normalized frequency\n","#train_df['Item_Popularity'] = train_df['Item_Identifier'].map(item_popularity)\n","#valid_df['Item_Popularity'] = valid_df['Item_Identifier'].map(item_popularity).fillna(0)  # unseen items → 0\n","\n","# ---------- Trial 2 - polynomial regression rmse - 1039 (Lowest rmse mentioned)\n","#train_df['Item_Sales_Frequency'] = (\n","#    np.log1p(train_df['Outlet_Age']) * (train_df['Item_MRP'] / (train_df['Item_Weight'] + 1)) * train_df['Item_Popularity']\n","#)\n","\n","#valid_df['Item_Sales_Frequency'] = (\n","#    np.log1p(valid_df['Outlet_Age']) * (valid_df['Item_MRP'] / (valid_df['Item_Weight'] + 1)) * valid_df['Item_Popularity']\n","#)\n","\n","# ---------- Trial 3 - polynomial regression - 1038.26 (Lowest rmse mentioned)\n","item_popularity = train_df['Item_Identifier'].value_counts(normalize=True)  # normalized frequency\n","\n","train_df['Item_Popularity'] = train_df['Item_Identifier'].map(item_popularity)\n","valid_df['Item_Popularity'] = valid_df['Item_Identifier'].map(item_popularity).fillna(0)  # unseen items → 0\n","\n","train_df['Item_Sales_Frequency'] = (\n","    np.log1p(train_df['Outlet_Age']) *\n","    ((train_df['Item_MRP'] - train_df['Item_MRP'].mean()) / (train_df['Item_MRP'].std() + 1)) *\n","    (train_df['Item_Popularity'] + 0.01)  # smoothing\n",")\n","\n","valid_df['Item_Sales_Frequency'] = (\n","    np.log1p(valid_df['Outlet_Age']) *\n","    ((valid_df['Item_MRP'] - valid_df['Item_MRP'].mean()) / (valid_df['Item_MRP'].std() + 1)) *\n","    (valid_df['Item_Popularity'] + 0.01)\n",")\n","\n","\n","# --- Handle Inf / NaN in Item_Sales_Frequency ---\n","train_df['Item_Sales_Frequency'].replace([np.inf, -np.inf], np.nan, inplace=True)\n","valid_df['Item_Sales_Frequency'].replace([np.inf, -np.inf], np.nan, inplace=True)\n","train_df['Item_Sales_Frequency'].fillna(train_df['Item_Sales_Frequency'].mean(), inplace=True)\n","valid_df['Item_Sales_Frequency'].fillna(valid_df['Item_Sales_Frequency'].mean(), inplace=True)"],"metadata":{"id":"yQcU2u49K8ua"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# --- Feature Engineering 2 : Customer Outlet Preference ---\n","outlet_type_sales = train_df.groupby('Outlet_Type')['Item_Outlet_Sales'].sum()\n","outlet_type_percentage = outlet_type_sales / outlet_type_sales.sum()\n","\n","train_df['Outlet_Type_Percentage'] = train_df['Outlet_Type'].map(outlet_type_percentage)\n","valid_df['Outlet_Type_Percentage'] = valid_df['Outlet_Type'].map(outlet_type_percentage)\n","\n","# ---------- Trial 3 - xgboost rmse - 1041\n","#train_df['Customer_Outlet_Preference'] = (\n","#    train_df['Item_MRP'] * train_df['Outlet_Type_Percentage'] / (train_df['Item_Weight']+1)*(train_df['Item_Visibility']+1)\n","#)\n","#valid_df['Customer_Outlet_Preference'] = (\n","#    valid_df['Item_MRP'] * valid_df['Outlet_Type_Percentage'] / (valid_df['Item_Weight']+1)*(valid_df['Item_Visibility']+1)\n","#)\n","\n","# polynomial regression - 1039\n","#median_mrp = df['Item_MRP'].median()\n","\n","#train_df['Customer_Outlet_Preference'] = (\n","#    ((train_df['Item_MRP'] / median_mrp) ** 0.5) *\n","#    np.exp(-train_df['Item_Visibility']) *\n","#    train_df['Outlet_Type_Percentage']\n","#)\n","\n","#valid_df['Customer_Outlet_Preference'] = (\n","#    ((valid_df['Item_MRP'] / median_mrp) ** 0.5) *\n","#    np.exp(-valid_df['Item_Visibility']) *\n","#    valid_df['Outlet_Type_Percentage']\n","#)\n","\n","\n","# ---------- Trial 2 - polynomial regression - 1038.26 (lowest rmse mentioned)\n","median_mrp = train_df['Item_MRP'].median()\n","\n","train_df['Customer_Outlet_Preference'] = (\n","    np.sqrt(train_df['Item_MRP'] / median_mrp) *\n","    (1 / (1 + np.log1p(train_df['Item_Visibility']))) *   # softer visibility penalty\n","    (train_df['Outlet_Type_Percentage'] * (1 / train_df['Outlet_Location_Type']))\n",")\n","\n","valid_df['Customer_Outlet_Preference'] = (\n","    np.sqrt(valid_df['Item_MRP'] / median_mrp) *\n","    (1 / (1 + np.log1p(valid_df['Item_Visibility']))) *\n","    (valid_df['Outlet_Type_Percentage'] * (1 / valid_df['Outlet_Location_Type']))\n",")"],"metadata":{"id":"Kczjb2fELVKz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Feature Engieering 3\n","# polynomial regression + Feature Engieering 1 + Feature Engieering 2 + Feature Engieering 3 - RMSE = 1038.14\n","\n","# 1. Price per weight\n","train_df['Price_per_Weight'] = train_df['Item_MRP'] / (train_df['Item_Weight'] + 1)\n","valid_df['Price_per_Weight'] = valid_df['Item_MRP'] / (valid_df['Item_Weight'] + 1)\n","\n","# 2. Visibility × Price interaction\n","train_df['Visibility_Price_Interaction'] = train_df['Item_Visibility'] * train_df['Item_MRP']\n","valid_df['Visibility_Price_Interaction'] = valid_df['Item_Visibility'] * valid_df['Item_MRP']\n","\n","# 3. Outlet Age × Outlet Type\n","train_df['Outlet_Age_Type'] = train_df['Outlet_Age'] * train_df['Outlet_Type']\n","valid_df['Outlet_Age_Type'] = valid_df['Outlet_Age'] * valid_df['Outlet_Type']\n","\n","# 4. Fat × Type interaction\n","train_df['Fat_Type_Interaction'] = train_df['Item_Fat_Content'] * train_df['Item_Type']\n","valid_df['Fat_Type_Interaction'] = valid_df['Item_Fat_Content'] * valid_df['Item_Type']\n","\n","# 5. Outlet diversity\n","outlet_diversity = train_df.groupby('Outlet_Identifier')['Item_Identifier'].nunique()\n","train_df['Outlet_Diversity'] = train_df['Outlet_Identifier'].map(outlet_diversity)\n","valid_df['Outlet_Diversity'] = valid_df['Outlet_Identifier'].map(outlet_diversity)\n","valid_df['Outlet_Diversity'].fillna(outlet_diversity.mean(), inplace=True)\n","\n","# 6. Log features\n","train_df['Log_MRP'] = np.log1p(train_df['Item_MRP'])\n","valid_df['Log_MRP'] = np.log1p(valid_df['Item_MRP'])\n","\n","train_df['Log_Visibility'] = np.log1p(train_df['Item_Visibility'])\n","valid_df['Log_Visibility'] = np.log1p(valid_df['Item_Visibility'])"],"metadata":{"id":"2-iQu1oMLso1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Normalize to 0-1 range (avoid gradient explosion)\n","#train_df['Customer_Outlet_Preference'] = (\n","#    (train_df['Customer_Outlet_Preference'] - train_df['Customer_Outlet_Preference'].min()) /\n","#    (train_df['Customer_Outlet_Preference'].max() - train_df['Customer_Outlet_Preference'].min())\n","#)\n","#valid_df['Customer_Outlet_Preference'] = (\n","#    (valid_df['Customer_Outlet_Preference'] - valid_df['Customer_Outlet_Preference'].min()) /\n","#    (valid_df['Customer_Outlet_Preference'].max() - valid_df['Customer_Outlet_Preference'].min())\n","#)"],"metadata":{"id":"L3lf7segLxdM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["features = [\n","    'Item_Weight', 'Item_Fat_Content', 'Item_Type', 'Item_MRP',\n","    'Item_Visibility', 'Outlet_Size', 'Outlet_Location_Type',\n","    'Outlet_Type', 'Outlet_Age',\n","    'Item_Sales_Frequency', 'Customer_Outlet_Preference',\n","    'Price_per_Weight', 'Visibility_Price_Interaction',\n","    'Outlet_Age_Type', 'Fat_Type_Interaction',\n","    'Outlet_Diversity', 'Log_MRP', 'Log_Visibility'\n","]\n","\n","\n","X = train_df[features]\n","y = train_df['Item_Outlet_Sales']\n","X_test_final = valid_df[features]\n","\n","# --- Train/Validation Split ---\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.25, random_state=42)"],"metadata":{"id":"Z3mQyL2-Pevy"},"execution_count":null,"outputs":[]}]}